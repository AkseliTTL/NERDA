{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('3.9.0')",
   "metadata": {
    "interpreter": {
     "hash": "36071112a161297f2fd106003050184fbdff34ed057f375faa6d2f5f0cad40eb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Workflow Examples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "`NERDA` offers a simple easy-to-use interface for fine-tuning and applying transformer-based models for Named-entity Recognition (='`NERDA` models'). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "`NERDA` can be used in two ways. You can either (1) train your own customized `NERDA` model or (2) download and use one of our precooked `NERDA` models for inference."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Train Your Own `NERDA` model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We want to fine-tune a transformer for Danish. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First, we download some ressources including a Danish NER dataset [DaNE](https://github.com/alexandrainst/danlp/blob/master/docs/docs/datasets.md#dane) with annotated Named Entities, that we will use for training and evaluation of our model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NERDA.datasets import get_dane_data, download_dane_data\n",
    "download_dane_data()\n",
    "import nltk\n",
    "nltk.download('punkt');\n"
   ]
  },
  {
   "source": [
    "\n",
    "The DaNE dataset looks like this (if you provide your own dataset, it must have the same structure, except it does not have to follow the IOB tagging scheme)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = get_dane_data('train', 5)\n",
    "validation = get_dane_data('dev', 5)\n",
    "training"
   ]
  },
  {
   "source": [
    "Instantiate a `NERDA` model for finetuning a multilingual BERT model. Note, this model configuration only uses 5 sentences for model training to minimize execution time. Also the hyperparameters for the model have chosen in order to minimize execution time. This example only serves to illustrate the functionality i.e. the resulting model will suck."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NERDA.models import NERDA\n",
    "training = get_dane_data('train', 5)\n",
    "validation = get_dane_data('dev', 5)\n",
    "model = NERDA(dataset_training = training,\n",
    "              dataset_validation = validation,\n",
    "              transformer = 'bert-base-multilingual-uncased',\n",
    "              hyperparameters = {'epochs' : 1,\n",
    "                                 'warmup_steps' : 10,\n",
    "                                 'train_batch_size': 5,\n",
    "                                 'learning_rate': 0.0001},)"
   ]
  },
  {
   "source": [
    "By default the network architecture is the same as the model in [Hvingelby et al. 2020](http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.565.pdf). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The model can then be trained by invoking the `train` method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "model.train()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "We can then compute the performance on a test set (limited to 5 sentences):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_dane_data('test', 5)\n",
    "model.evaluate_performance(test)"
   ]
  },
  {
   "source": [
    "Unsurprisingly, the model sucks in this case due to the ludicrous specification."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Named Entities in new texts can be predicted with `predict` functions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danish: 'Jens Hansen har en bondegård' = English: 'Old MacDonald has a farm'\n",
    "text = \"Jens Hansen har en bondegård\"\n",
    "model.predict_text(text)"
   ]
  },
  {
   "source": [
    "`NERDA` has more handles, that you can use. You can (1) provide your own data set, (2) choose whatever pretrained transformer you like to fine-tune, (3) provide your own set of hyperparameters and lastly (4) provide your own `torch` network (architecture)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We have trained a number of more reasonable model configurations, that you can use. See the chapter below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Use a Precooked `NERDA` model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We have precooked a number of `NERDA` models, that you can download \n",
    "and use right off the shelf. \n",
    "\n",
    "Here is an example.\n",
    "\n",
    "Instantiate Danish ELECTRA model, that has been finetuned for NER in Danish,\n",
    "`ELECTRA_DA_DaNE`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from NERDA.precooked import ELECTRA_DA_DaNE\n",
    "model = ELECTRA_DA_DaNE()\n",
    "\n"
   ]
  },
  {
   "source": [
    "(Down)load network:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.download_network()\n",
    "model.load_network()\n"
   ]
  },
  {
   "source": [
    "This model performs much better:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_performance(get_dane_data('test', 100))"
   ]
  },
  {
   "source": [
    "Predict named entities in new texts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Danish) text to identify named entities in.\n",
    "# = 'Old MacDonald had a farm'\n",
    "text = 'Jens Hansen har en bondegård'\n",
    "model.predict_text(text)\n"
   ]
  },
  {
   "source": [
    "### List of Precooked Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The table below shows the precooked `NERDA` models publicly available for download.\n",
    "\n",
    "| **Model**       | **Language** | **Transformer**   | **F1-score** |  \n",
    "|-----------------|--------------|-------------------|--------------|\n",
    "| `DA_BERT_ML`    | Danish       | [Multilingual BERT](https://huggingface.co/bert-base-multilingual-uncased) | xx.x       |\n",
    "| `DA_ELECTRA_DA` | Danish       | [Danish ELECTRA](https://huggingface.co/Maltehb/-l-ctra-danish-electra-small-uncased) | yy.y             |\n",
    "| `EN_BERT_ML`    | English      | [Multilingual BERT](https://huggingface.co/bert-base-multilingual-uncased)| zz.z              |\n",
    "\n",
    "Note, that we have not spent a lot of time on actually fine-tuning the models,\n",
    "so there could be room for improvement. If you are able to improve the models,\n",
    "we will be happy to hear from you and include your `NERDA` model.\n",
    "\n",
    "## Performance\n",
    "\n",
    "The table below summarizes the performance as measured by F1-scores of the model\n",
    " configurations, that `NERDA` ships with. \n",
    "\n",
    "| **Level**     | **MBERT** | **DABERT** | **ELECTRA** | **XLMROBERTA** | **DISTILMBERT** |\n",
    "|---------------|-----------|------------|-------------|----------------|-----------------|\n",
    "| B-PER         | 0.92      | 0.93       | 0.92        | 0.94           | 0.89            |      \n",
    "| I-PER         | 0.97      | 0.99       | 0.97        | 0.99           | 0.96            |   \n",
    "| B-ORG         | 0.68      | 0.79       | 0.65        | 0.78           | 0.66            |     \n",
    "| I-ORG         | 0.67      | 0.79       | 0.72        | 0.77           | 0.61            |   \n",
    "| B-LOC         | 0.86      | 0.85       | 0.79        | 0.87           | 0.80            |     \n",
    "| I-LOC         | 0.33      | 0.32       | 0.44        | 0.24           | 0.29            |     \n",
    "| B-MISC        | 0.73      | 0.74       | 0.61        | 0.77           | 0.70            |     \n",
    "| I-MISC        | 0.70      | 0.86       | 0.65        | 0.91           | 0.61            |   \n",
    "| **AVG_MICRO** | 0.81      | 0.85       | 0.79        | 0.86           | 0.78            |      \n",
    "| **AVG_MACRO** | 0.73      | 0.78       | 0.72        | 0.78           | 0.69            |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}